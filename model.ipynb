{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "import pickle\n",
    "import re\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making lists to append all tweets/data to\n",
    "real = []\n",
    "satire = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sntwitter to scrape tweets and append data to lists\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:cnnbrk').get_items()):\n",
    "    if i>5000:\n",
    "        break\n",
    "    real.append([tweet.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:enews').get_items()):\n",
    "    if i>5000:\n",
    "        break\n",
    "    real.append([tweet.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.DataFrame(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.to_csv('/Users/lucashawranke/Documents/data-science/sarcasm-scanner/data/real_tweets.csv') #mac\n",
    "# real.to_csv('/Users/lucas/data-science/sarcasm-scanner/data/real_tweets.csv') #pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nick Cannon is getting some rest after coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Team USA eliminated from the World Cup after a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man has been arrested and charged with murde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right-wing conspiracy theorist Alex Jones file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America added a robust 263,000 jobs last month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Selma Blair's Surprise 2022 Emmys Appearance S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Someone sedate E! ❤️ Sandra Oh had a mini Grey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Tori Spelling's Best Friend and \"Guncle\" Scout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Zendaya and More Best Dressed Stars at the 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Pete Davidson Makes Surprise Appearance at 202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10002 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      Nick Cannon is getting some rest after coming ...\n",
       "1      Team USA eliminated from the World Cup after a...\n",
       "2      A man has been arrested and charged with murde...\n",
       "3      Right-wing conspiracy theorist Alex Jones file...\n",
       "4      America added a robust 263,000 jobs last month...\n",
       "...                                                  ...\n",
       "9997   Selma Blair's Surprise 2022 Emmys Appearance S...\n",
       "9998   Someone sedate E! ❤️ Sandra Oh had a mini Grey...\n",
       "9999   Tori Spelling's Best Friend and \"Guncle\" Scout...\n",
       "10000  Zendaya and More Best Dressed Stars at the 202...\n",
       "10001  Pete Davidson Makes Surprise Appearance at 202...\n",
       "\n",
       "[10002 rows x 1 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:theonion').get_items()):\n",
    "    if i>5000:\n",
    "        break\n",
    "    satire.append([tweet.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:clickhole').get_items()):\n",
    "    if i>5000:\n",
    "        break\n",
    "    satire.append([tweet.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "satire = pd.DataFrame(satire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "satire.to_csv('/Users/lucashawranke/documents/data-science/sarcasm-scanner/data/satire_tweets.csv') #pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every Member Of Police Department Excitedly Vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://t.co/gi2PUyNBqZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zoo Assures Public Escaped Leopard Will Kill T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chobani Recalls Thousands Of Yogurts That Gave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://t.co/yDexD4IuWw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Are You A Widow? https://t.co/UWZLPewsKD https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Michael B. Jordan Said What?! https://t.co/y4F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Did ‘Sesame Street’ Go Too Far With Its Episod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Close Fucking Call: This Product That Got A Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Oh fuck. https://t.co/HQEBco5XzS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10002 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      Every Member Of Police Department Excitedly Vo...\n",
       "1                                https://t.co/gi2PUyNBqZ\n",
       "2      Zoo Assures Public Escaped Leopard Will Kill T...\n",
       "3      Chobani Recalls Thousands Of Yogurts That Gave...\n",
       "4                                https://t.co/yDexD4IuWw\n",
       "...                                                  ...\n",
       "9997   Are You A Widow? https://t.co/UWZLPewsKD https...\n",
       "9998   Michael B. Jordan Said What?! https://t.co/y4F...\n",
       "9999   Did ‘Sesame Street’ Go Too Far With Its Episod...\n",
       "10000  Close Fucking Call: This Product That Got A Ne...\n",
       "10001                   Oh fuck. https://t.co/HQEBco5XzS\n",
       "\n",
       "[10002 rows x 1 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.columns = ['Tweets']\n",
    "satire.columns = ['Tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['Authenticity'] = 'real'\n",
    "satire['Authenticity'] = 'satire'\n",
    "df = pd.concat([real, satire])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Authenticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nick Cannon is getting some rest after coming ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Team USA eliminated from the World Cup after a...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man has been arrested and charged with murde...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right-wing conspiracy theorist Alex Jones file...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America added a robust 263,000 jobs last month...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Are You A Widow? https://t.co/UWZLPewsKD https...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Michael B. Jordan Said What?! https://t.co/y4F...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Did ‘Sesame Street’ Go Too Far With Its Episod...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Close Fucking Call: This Product That Got A Ne...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Oh fuck. https://t.co/HQEBco5XzS</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets Authenticity\n",
       "0      Nick Cannon is getting some rest after coming ...         real\n",
       "1      Team USA eliminated from the World Cup after a...         real\n",
       "2      A man has been arrested and charged with murde...         real\n",
       "3      Right-wing conspiracy theorist Alex Jones file...         real\n",
       "4      America added a robust 263,000 jobs last month...         real\n",
       "...                                                  ...          ...\n",
       "9997   Are You A Widow? https://t.co/UWZLPewsKD https...       satire\n",
       "9998   Michael B. Jordan Said What?! https://t.co/y4F...       satire\n",
       "9999   Did ‘Sesame Street’ Go Too Far With Its Episod...       satire\n",
       "10000  Close Fucking Call: This Product That Got A Ne...       satire\n",
       "10001                   Oh fuck. https://t.co/HQEBco5XzS       satire\n",
       "\n",
       "[20004 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['Tweets'] = real['Tweets'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "satire['Tweets'] = satire['Tweets'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Authenticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nick Cannon is getting some rest after coming ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Team USA eliminated from the World Cup after a...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man has been arrested and charged with murde...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right-wing conspiracy theorist Alex Jones file...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America added a robust 263,000 jobs last month...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Selma Blair's Surprise 2022 Emmys Appearance S...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Someone sedate E! ❤️ Sandra Oh had a mini Grey...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Tori Spelling's Best Friend and \"Guncle\" Scout...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Zendaya and More Best Dressed Stars at the 202...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Pete Davidson Makes Surprise Appearance at 202...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets Authenticity\n",
       "0      Nick Cannon is getting some rest after coming ...         real\n",
       "1      Team USA eliminated from the World Cup after a...         real\n",
       "2      A man has been arrested and charged with murde...         real\n",
       "3      Right-wing conspiracy theorist Alex Jones file...         real\n",
       "4      America added a robust 263,000 jobs last month...         real\n",
       "...                                                  ...          ...\n",
       "9997   Selma Blair's Surprise 2022 Emmys Appearance S...         real\n",
       "9998   Someone sedate E! ❤️ Sandra Oh had a mini Grey...         real\n",
       "9999   Tori Spelling's Best Friend and \"Guncle\" Scout...         real\n",
       "10000  Zendaya and More Best Dressed Stars at the 202...         real\n",
       "10001  Pete Davidson Makes Surprise Appearance at 202...         real\n",
       "\n",
       "[10002 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Authenticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nick Cannon is getting some rest after coming ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Team USA eliminated from the World Cup after a...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man has been arrested and charged with murde...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right-wing conspiracy theorist Alex Jones file...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America added a robust 263,000 jobs last month...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Are You A Widow? https://t.co/UWZLPewsKD https...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Michael B. Jordan Said What?! https://t.co/y4F...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Did ‘Sesame Street’ Go Too Far With Its Episod...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Close Fucking Call: This Product That Got A Ne...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Oh fuck. https://t.co/HQEBco5XzS</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets Authenticity\n",
       "0      Nick Cannon is getting some rest after coming ...         real\n",
       "1      Team USA eliminated from the World Cup after a...         real\n",
       "2      A man has been arrested and charged with murde...         real\n",
       "3      Right-wing conspiracy theorist Alex Jones file...         real\n",
       "4      America added a robust 263,000 jobs last month...         real\n",
       "...                                                  ...          ...\n",
       "9997   Are You A Widow? https://t.co/UWZLPewsKD https...       satire\n",
       "9998   Michael B. Jordan Said What?! https://t.co/y4F...       satire\n",
       "9999   Did ‘Sesame Street’ Go Too Far With Its Episod...       satire\n",
       "10000  Close Fucking Call: This Product That Got A Ne...       satire\n",
       "10001                   Oh fuck. https://t.co/HQEBco5XzS       satire\n",
       "\n",
       "[20004 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/lucashawranke/Documents/data-science/sarcasm-scanner/data/df.csv') #mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating/Running MultinomialNB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = real[:8000]\n",
    "X_test = real[-2000:]\n",
    "\n",
    "y_train = satire[:8000]\n",
    "y_test = satire[-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9087728067983004\n",
      "confusion matrix:  [[1925   91]\n",
      " [ 274 1711]]\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('nb', mnb)])\n",
    "pipe.fit(train.Tweets, train.Authenticity)\n",
    "\n",
    "predictions = pipe.predict(test.Tweets)\n",
    "print('accuracy: ', accuracy_score(test['Authenticity'], predictions))\n",
    "print('confusion matrix: ', confusion_matrix(test['Authenticity'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, this model has an accuracy of 90.8%. Although we might be able to do better, let's test it out and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['satire']\n"
     ]
    }
   ],
   "source": [
    "headline = np.array([[\"ISIS Takes Credit For Relatives Overstaying Welcome At Thanksgiving\"]])\n",
    "predictions = pipe.predict(headline[0])\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct! This article is from [a different](https://web.archive.org/web/20221204015813/http://www.cap-news.com/) satire news site. Let's save the model either way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lucashawranke/Documents/data-science/sarcasm-scanner/mnb.pkl']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe, '/Users/lucashawranke/Documents/data-science/sarcasm-scanner/mnb.pkl') #mac\n",
    "# joblib.dump(pipe, '/Users/lucas/data-science/sarcasm-scanner/model.pkl') #pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mac\n",
    "# with open('/Users/lucashawranke/Documents/data-science/sarcasm-scanner/model.pkl', 'wb') as files:\n",
    "#     pickle.dump(pipe, files)\n",
    "#pc\n",
    "# with open('/Users/lucas/data-science/sarcasm-scanner/model.pkl', 'wb') as files:\n",
    "#     pickle.dump(pipe, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LinearSVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9492626843289178\n",
      "confusion matrix: [[1890  126]\n",
      " [  77 1908]]\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('svc', svc)])\n",
    "pipe.fit(train.Tweets, train.Authenticity)\n",
    "predictions = pipe.predict(test.Tweets)\n",
    "print('accuracy: ', accuracy_score(test['Authenticity'], predictions))\n",
    "print('confusion matrix:', confusion_matrix(test['Authenticity'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving LinearSVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lucashawranke/documents/data-science/sarcasm-scanner/lsvc.pkl']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe, '/Users/lucashawranke/documents/data-science/sarcasm-scanner/lsvc.pkl') #mac\n",
    "# joblib.dump(pipe, '/Users/lucas/data-science/sarcasm-scanner/model2.pkl') #pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.939265183704074\n",
      "confusion matrix: [[1855  161]\n",
      " [  82 1903]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('lr', lr)])\n",
    "pipe.fit(train.Tweets, train.Authenticity)\n",
    "predictions = pipe.predict(test.Tweets)\n",
    "print('accuracy: ', accuracy_score(test['Authenticity'], predictions))\n",
    "print('confusion matrix:', confusion_matrix(test['Authenticity'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9232691827043239\n",
      "confusion matrix: [[1822  194]\n",
      " [ 113 1872]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('rf', rf)])\n",
    "pipe.fit(train.Tweets, train.Authenticity)\n",
    "predictions = pipe.predict(test.Tweets)\n",
    "print('accuracy: ', accuracy_score(test['Authenticity'], predictions))\n",
    "print('confusion matrix:', confusion_matrix(test['Authenticity'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8470382404398901\n",
      "confusion matrix: [[1575  441]\n",
      " [ 171 1814]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('dt', dt)])\n",
    "pipe.fit(train.Tweets, train.Authenticity)\n",
    "predictions = pipe.predict(test.Tweets)\n",
    "print('accuracy: ', accuracy_score(test['Authenticity'], predictions))\n",
    "print('confusion matrix:', confusion_matrix(test['Authenticity'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8780304923769058\n",
      "confusion matrix: [[1843  173]\n",
      " [ 315 1670]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('knn', knn)])\n",
    "pipe.fit(train.Tweets, train.Authenticity)\n",
    "predictions = pipe.predict(test.Tweets)\n",
    "print('accuracy: ', accuracy_score(test['Authenticity'], predictions))\n",
    "print('confusion matrix:', confusion_matrix(test['Authenticity'], predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cc3b03a9a7e4010a291141970bf1cb2053c725e17844b2b26603859505c2b66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
